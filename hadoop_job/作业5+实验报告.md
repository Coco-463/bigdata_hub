# 作业5 实验报告

## 1 集群环境运行

### 1.1 准备集群环境

```
~$ sudo docker start h01 h02 h03 h04 h05
~$ sudo docker exec -it h01 /bin/bash
```

将节点全部start，实际只用运行主节点h01

```
root@h01:/usr/local/hadoop/sbin# ./start-all.sh
```

开始运行

### 1.2 将文件导入至hdfs

```
~$ sudo docker cp ~/bigdata_workspace/analyst_ratings.csv e5c3902c27e5:/tmp
~$ sudo docker cp ~/bigdata_workspace/stop-word-list.txt e5c3902c27e5:/tmp
```

使用`~$ sudo docker cp <需要传输的文件路径> <容器id>:<传输文件在容器中的存放位置>`将文件从本机暂存至容器h01的根目录下的tmp中（其中容器id由`sudo docker ps`查看）

```
root@h01:/usr/local/hadoop# ./bin/hdfs dfs -put /tmp/analyst_ratings.csv /input/
root@h01:/usr/local/hadoop# ./bin/hdfs dfs -put /tmp/stop-word-list.txt /input/
```

将暂存于tmp下的文件们移动至hdfs下的input中

通过 `./bin/hdfs dfs -ls /input`查看结果

![ls input](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{0F43F078-7C2C-432C-B8F2-AB6B0EF70D45}.png)

### 1.3 导入代码

在本地使用maven管理java文件

```
~/bigdata_workspace/hadoop_job$ mvn clean package
```

在终端下运行命令

`clean`在进行打包之前，先确保没有旧的编译文件

`package`将项目打包成 `.jar` 文件，放在 `target` 目录下

```
~$ sudo docker cp ~/bigdata_workspace/hadoop_job/target/hadoop_job-1.0-SNAPSHOT.jar e5c3902c27e5:/usr/local/hadoop
```

将包含Java代码的打包好的.jar传入容器

通过`root@h01:/usr/local/hadoop# jar tf hadoop_job-1.0-SNAPSHOT.jar`查看.jar下的文件

![查看.jar](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{811C5E11-6082-4DA8-8EBB-FA0B18C062D6}.png)

### 1.4 运行MapReduce代码

#### 任务1

```
#运行任务1
root@h01:/usr/local/hadoop# ./bin/hadoop jar hadoop_job-1.0-SNAPSHOT.jar com.example.StockCount /input/analyst_ratings.csv /output/SCout
```

![SC运行](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{C2DB92A3-E085-4931-A2F5-EA9D3088ED87}.png)

```
root@h01:/usr/local/hadoop# ./bin/hadoop fs -ls /output/WCout
#查看输出结果
root@h01:/usr/local/hadoop# ./bin/hadoop fs -cat /output/SCout/part-r-00000
```

![SC输出](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{636A23AD-27C6-462E-9DE3-B7DAB823DBBF}.png)

##### Browse Directory

展示web界面如下：

![SCweb](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{18D37FAF-DC93-4378-A6AF-42F7EA0A2F68}.png)

#### 任务2

与任务1类似，仅展示结果

![WC运行](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{47A030A6-E5DC-4E54-960D-CACA110B38F5}.png)

![WC输出](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{0A602ECE-E27F-4C39-93E7-92FF9C37A440}.png)

##### Browse Directory

![WCweb](D:\各种课程资料\大三上\金融大数据\作业\作业5\作业5 报告\{81AE6908-F614-40C9-9B2B-EF6FDB3701D1}.png)



### 1.5输出结果传回主机

```
#暂存到tmp下
root@h01:/usr/local/hadoop# ./bin/hdfs dfs -get /output/WCout/part-r-00000 /tmp
#从h01移动到主机的bigdata_workspace文件夹下
sudo docker cp e5c3902c27e5:/tmp/part-r-00000 ~/bigdata_workspace
```

## 3 设计思路与改进

#### 任务一

##### 思路

代码目的是从 CSV 文件中统计上市公司股票代码（“stock” 列）的出现次数，并按出现次数从大到小输出。主要包含三个部分：Mapper、Reducer 和Driver类。

1. **Mapper 类（`StockMapper`）**：
   - 继承自 `Mapper`，输入为每一行数据。
   - 将每一行按逗号分割成列，并检查是否存在有效的股票代码。
   - 对于每个有效的股票代码，输出键（股票代码）和值（1），以便在 Reducer 中进行统计。
2. **Reducer 类（`StockReducer`）**：
   - 继承自 `Reducer`，将 Mapper 输出的股票代码聚合。
   - 使用HashMap `occurrencesMap` 记录每个股票代码的出现次数。
   - 在 `cleanup` 方法中，对结果进行排序，并按格式输出排名、股票代码和出现次数。
3. **Driver类（`main` ）**：
   - 设置作业的配置，包括 Mapper 和 Reducer 的类，以及输入输出路径。
   - 启动 MapReduce 作业。

##### 改进

1. **性能不足**

- **排序效率**：
  - 目前使用 `List` 进行排序，在数据量较大时可能会很慢。考虑使用更高效的数据结构，比如 `PriorityQueue`，来优化排序操作。
- **内存使用**：
  - 在 Reducer 中使用了一个 HashMap 来存储所有股票代码及其出现次数，可能导致内存使用量过大，尤其在处理大规模数据集时。考虑使用更为紧凑的存储结构，但暂时还不知道可以如何改进。

2. **扩展性不足**

- **硬编码列索引**：
  - 获取股票代码时， `columns.length == 4 && !columns[3].equals("stock")` 假设数据有固定的列数，这降低了代码的灵活性。可以使用配置文件或参数化输入来动态指定要处理的列索引。
- **缺乏容错处理**：
  - 代码缺少对输入数据的异常情况（如格式不正确、缺失值等）进行处理。可以适当增加异常性处理。

#### 任务二

##### 思路

代码用于从上市公司热点新闻标题数据集中统计高频单词。具体步骤包括读取停词列表、处理标题、统计单词出现次数，并输出出现频率最高的前 100 个单词。主要包含以下几个部分：

1. **Mapper 类（`WordMapper`）**：
   - 在 `setup` 方法中，读取停词文件，将其加载到内存中的集合 `stopWords` 中，以便在后续的单词统计中进行过滤。
   - 在 `map` 方法中，从输入的每一行中提取“headline”列，将其转换为小写并清理标点符号，分割成单词。
   - 对于每个不在停词列表中的单词，输出该单词和计数（1）。
2. **Reducer 类（`WordReducer`）**：
   - 在 `reduce` 方法中，接收相同单词的计数，将其累加并存储到 `wordCountMap` 中。
   - 在 `cleanup` 方法中，按出现次数对 `wordCountMap` 进行排序，并输出前 100 个高频单词及其出现次数。
3. **主类（`main` 方法）**：
   - 配置和设置 MapReduce 作业，指定输入输出路径，并提交作业。

##### 改进

1. **性能不足**

- **内存使用**：
  - 当前实现将所有单词及其计数存储在内存中，如果数据集非常大，可能导致内存溢出。可以考虑使用外部排序或数据库存储，以处理大量数据。
- **停词加载效率**：
  - 停词列表在每个 Mapper 实例中加载，如果有多个 Mapper 实例，会造成多次重复读取。可以考虑使用分布式缓存（Distributed Cache）将停词文件传递给所有 Mapper，从而提高效率。

2. **扩展性不足**

- **硬编码路径**：
  - 停词文件路径被硬编码为 `hdfs://h01:9000/input/stop-word-list.txt`，这降低了代码的灵活性。可以将其改为通过命令行参数传递，使程序更灵活。
