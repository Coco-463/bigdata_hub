### 任务一：每日资金流入流出统计 

#### 任务概述

根据 user_balance_table 表中的数据，编写 MapReduce 程序，统计所有⽤户每⽇的资⾦流⼊与 流出情况。资⾦流⼊意味着申购⾏为，资⾦流出为赎回⾏为。

#### 设计思路

**1.自定义 Writable 类型 `Amounts`：**

- **类功能**：`Amounts` 类用于封装每个日期的资金购买（purchase）和赎回（redeem）金额，确保 Mapper 和 Reducer 之间能够传递自定义对象。
- **序列化**：实现了 `Writable` 接口，通过 `write()` 和 `readFields()` 方法进行数据的序列化和反序列化。`toString()` 方法返回资金的字符串表示，便于输出。

**2.Mapper :**

- **输入**：每行数据是一个文本记录，包含多个字段。Mapper 从中提取日期、购买金额和赎回金额。
- **日期键**：提取第 1 列作为日期（`fields[1]`），作为输出的键。
- **金额处理**：通过 `parseDouble()` 方法解析购买金额（`fields[4]`）和赎回金额（`fields[8]`），并创建一个新的 `Amounts` 对象保存这两个值。
- **输出**：以日期为键，将 `Amounts` 对象作为值输出，格式为 `<date, Amounts>`。

**3.Reducer:**

- **输入**：Reducer 收到来自 Mapper 的数据，按日期（键）聚合 `Amounts` 对象。
- **聚合**：对每个日期的 `Amounts` 对象进行求和，计算总的购买金额和赎回金额。
- **输出**：输出每个日期的总购买和赎回金额，格式为 `<date, totalPurchase,totalRedeem>`。

**4.main:**

- **作业配置**：配置 Hadoop 作业，指定输入路径和输出路径，设置 Mapper 和 Reducer 类，指定输出的键值类型。
- **执行作业**：调用 `job.waitForCompletion(true)` 启动作业并等待执行完成。

#### 输出结果

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{D4098B5E-027E-4D23-AF77-1F62AD7FBE1E}.png" alt="{D4098B5E-027E-4D23-AF77-1F62AD7FBE1E}" style="zoom:70%;" />

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{5AE82BF8-9D5C-4BBC-8380-48B98026F966}.png" alt="{5AE82BF8-9D5C-4BBC-8380-48B98026F966}" style="zoom:50%;" />



### 任务二：星期交易量统计 

#### 任务概述

基于任务⼀的结果，编写 MapReduce 程序，统计⼀周七天中每天的平均资⾦流⼊与流出情况，并按照资金流入量从大到小排序。

#### 设计思路

**1.Mapper：**

- **解析输入数据**：每行输入包含日期和资金流入流出量。Mapper 通过 `SimpleDateFormat` 将日期字符串解析为 `Date` 对象，接着利用 `Calendar` 类提取出星期几（如 "Monday", "Tuesday"）。

- **分组数据**：将数据按照星期几进行分组，即输出的键为星期几（如 "Monday"），值为资金流入和流出量。这里假设每行的数据格式是“日期（yyyyMMdd） + 资金流入量,资金流出量”，通过逗号分隔。
- **输出格式**：输出 `<weekday, flowAmounts>`，其中 `weekday` 是星期几的名称，`flowAmounts` 是资金流入和流出量的字符串。

**2.Reducer：**

- **聚合数据**：Reducer 接收来自 Mapper 按星期几分组的所有数据。对于每个星期几，将资金流入和流出量累加，并计算日均值。
- **计算平均值**：每个星期几的总流入量和总流出量除以该星期几的记录数量，得到日均流入量和流出量。
- **排序与输出**：Reducer 还负责将星期几按资金流入量降序排序，并输出结果。

**3.main：**

- 配置 MapReduce 作业，设置输入输出路径，启动作业并执行。

#### 运行结果

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{8A197F0A-DCFB-4200-8F0A-FD5DC087BE91}.png" alt="{8A197F0A-DCFB-4200-8F0A-FD5DC087BE91}" style="zoom:70%;" />

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{BD632BAF-F470-4E98-875C-C7C1D7C3A384}.png" alt="{BD632BAF-F470-4E98-875C-C7C1D7C3A384}" style="zoom:50%;" />



### 任务三：用户活跃度分析 

#### 任务概述

根据 user_balance_table  表中的数据，编写 MapReduce 程序，统计每个⽤户的活跃天数，并按 照活跃天数降序排列。当⽤户当⽇有直接购买（ direct_purchase_amt  字段⼤于 0 ）或赎回⾏为（ 字段⼤于 0 ）时，则该⽤户当天活跃。

#### 设计思路

**1.Mapper：**

- 读取输入数据并提取每行的用户 ID 和资金流入流出信息。
- 判断该用户是否符合活跃条件（如 `directPurchaseAmt > 0` 或 `totalRedeemAmt > 0`）。
- 如果用户符合条件，输出 `<userId, 1>`，表示该用户在某一天活跃。

**2.Reducer：**

- 聚合来自 Mapper 的用户活跃记录，计算每个用户的活跃天数（即用户出现的次数）。
- 将每个用户的活跃天数存储在 `userActiveDaysMap` 中。

**3.排序与输出：**

- 在 `cleanup` 方法中，将 `userActiveDaysMap` 中的用户按活跃天数降序排序。
- 输出每个用户的 ID 和活跃天数。

**4.main：**

- 配置和启动 MapReduce 作业，设置输入输出路径和相关参数，执行作业并返回结果。

#### 运行结果

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{9D90625C-E8B1-4D8C-B9D6-CA2FE6B864FC}.png" alt="{9D90625C-E8B1-4D8C-B9D6-CA2FE6B864FC}" style="zoom:70%;" />

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{6630A3FE-16EE-46CE-9B7D-D90615395DF9}.png" alt="{6630A3FE-16EE-46CE-9B7D-D90615395DF9}" style="zoom:70%;" />

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{AB99C999-61FC-438C-AB5A-3D99CE2CBC87}.png" alt="{AB99C999-61FC-438C-AB5A-3D99CE2CBC87}" style="zoom:50%;" />



### 任务四：交易行为影响因素分析

我考虑的是过去7天日均收益率（参考⽀付宝收益率表 fd_day_share_interest ）对申购 / 赎回行为的影响，将日均收益率分为了5个区间，利用任务一获得的每日资金流入流出量，算出过去7天日均收益率在每个区间中所有日期的平均资金流入流出量。

#### 任务概述

根据 fd_day_share_interest 表，编写一个MapReduce程序，将过去 7 天的每日收益率mfd_7daily_yield 划分为不同的区间（4到4.5、4.5到5、5到5.5、5.5到6、大于6，五个区间分别标号1、2、3、4、5），统计每个区间下的日均资金流入和流出总量，其中每天的资金流入和流出量是由任务一得出的。最终统计的输出格式为：  < 区间标号 > TAB < 日均资⾦流⼊量  >,< 日均资⾦流出量 > 例如： 2     32488348,5525022

#### 设计思路

**1.Mapper：**

- 读取输入数据并提取每行的收益率（yield）、资金流入量（inflow）和资金流出量（outflow）。
- 根据收益率将数据分为不同的区间（如 4%-4.5%、4.5%-5% 等）。定义了 `getInterval()` 方法来为每条记录分配一个收益区间。
- 将每条记录的流入量（正值）和流出量（负值）分别输出，键是区间编号，值是资金流量。

**2.Reducer：**

- 聚合来自 Mapper 的数据，分别计算每个收益区间的资金流入和流出量的总和。
- 计算日均流入和流出量，通过将总流入和总流出除以记录的数量来得到平均值。
- 输出每个收益区间的平均流入和流出量。

**3.main：**

- 配置并启动 MapReduce 作业，设置输入输出路径和相关参数，执行作业并返回结果。

#### 运行结果

![{BA9E30EC-3D3E-493E-9FFB-38320E0A587E}](D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{BA9E30EC-3D3E-493E-9FFB-38320E0A587E}.png)

<img src="D:\各种课程资料\大三上\金融大数据\实验\实验二\实验报告\{7F9BF275-2B8F-4CB7-9F5C-D8DE1B4B3D53}.png" alt="{7F9BF275-2B8F-4CB7-9F5C-D8DE1B4B3D53}" style="zoom:70%;" />

#### 分析

查阅资料显示利率与基金或理财产品的申购（买入）和赎回（卖出）之间有密切的关系，尤其在货币基金、债券基金等固定收益类产品中。一般来说，利率的变化会影响投资者的收益预期，从而影响他们的申购或赎回行为。以下是一些关键关系：

1. **利率上升时，申购减少、赎回增加**

- 当市场利率上升时，银行存款、债券等固定收益类产品的收益率通常会变高，吸引更多投资者转向这些产品。
- 对于收益相对固定的货币基金或债券基金，投资吸引力会下降，因此投资者更倾向于赎回这些基金，将资金转向收益更高的产品。
- **影响**：申购量减少，赎回量增加，尤其是在低利率环境中吸引的资金容易流出。

2. **利率下降时，申购增加、赎回减少**

- 当市场利率下降时，固定收益产品（如银行存款）收益降低，投资者更倾向于寻求替代的理财产品。
- 货币基金、债券基金等产品在利率下降的环境中变得相对有吸引力，因为这些产品的收益率波动可能较小且风险相对较低。
- **影响**：申购量增加，赎回量减少，资金流入量通常增加。



然而运行代码统计的输出结果大致显示随利率的上升（区间1到5），资金流入量增长、资金流出量波动。我认为这是区间分块较为粗略且数据日期较少导致的结果不符合一般规律。

### 主要命令行

```
#开启各节点
~$ sudo docker start h01 h02 h03 h04 h05
~$ sudo docker exec -it h01 /bin/bash

#查看各容器
sudo docker ps

#在主节点中开启运行
root@h01:/usr/local/hadoop/sbin# ./start-all.sh

#使用maven打包上代码
mvn clean package

#代码传入容器
sudo docker cp ~/bigdata_workspace/lab2/hadooplab2/target/hadooplab2-1.0-SNAPSHOT.jar e5c3902c27e5:/usr/local/hadoop

#查看.jar目录
jar tf hadooplab2-1.0-SNAPSHOT.jar

#运行MapReduce程序
./bin/hadoop jar hadooplab2-1.0-SNAPSHOT.jar com.example.ActiveDay /input/user_balance_table.csv /output/ADout

#查看output目录
./bin/hadoop fs -ls /output/ADout

#查看输出结果
./bin/hadoop fs -cat /output/ADout/part-r-00000

#递归删除output目录下的输出
./bin/hadoop fs -rm -r /output/ADout

#更改输出文件的名字
./bin/hdfs dfs -get /output/FIOout/part-r-00000 /tmp/new_name.txt

#将输出文件传回主机
sudo docker cp e5c3902c27e5:/tmp/part-r-00000_AD ~/bigdata_workspace/lab2/hadooplab2/output

#关闭所有节点
root@h01:/usr/local/hadoop/sbin# ./stop-all.sh
```

### 改进

任务4中使用到的任务1的输出结果是人为添加到csv表格中的，这种方法一方面有损于数据的精度，另一方面如果数据量较大或是数据较复杂实现起来会比较困难。

然而在实际操作当中不知道运行一个MapReduce如何有两个输入文件，试行过`./bin/hadoop jar hadooplab2-1.0-SNAPSHOT.jar com.example.InterestDayAverage /input/mfd_bank_shibor.csv /output/FIOout/part-r-00000 /output/IDAout`，但是会报错，会将

`/output/FIOout/part-r-00000`当作输出目录。

后续改进可以考虑先编写程序进行两个输入文件的合并，然后再进行MapReduce。